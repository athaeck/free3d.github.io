<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="description"
        content="This student research project from our university is about recording a full three-dimensional (3D) scene using only three Azure Kinect cameras.">
    <meta name="keywords" content="Gaussian Splatting, Kinect, NeRF">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Free3D - Free-viewpoint 3D video creation</title>
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="icon" href="">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
</head>

<body>
    <nav class="navbar" role="navigation" aria-label="main navigation">
        <div class="navbar-brand">
            <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
                <span aria-hidden="true"></span>
                <span aria-hidden="true"></span>
                <span aria-hidden="true"></span>
            </a>
        </div>
        <div class="navbar-menu">
            <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
                <a class="navbar-item" href="https://github.com/HFU-DM-free3D">
                    <span class="icon">
                        <i class="fas fa-home"></i>
                    </span>
                </a>
            </div>
        </div>
    </nav>
    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">Free3D - Free-viewpoint 3D video creation</h1>
                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                <a href="https://github.com/felixChB">Felix Brunn</a>

                                ,
                            </span>
                            <span class="author-block">
                                <a href="https://github.com/pretteter">Jan Christmeier</a>

                                ,
                            </span>
                            <span class="author-block">
                                <a href="https://github.com/athaeck">Nick Philipp HÃ¤cker</a>

                                ,
                            </span>
                            <span class="author-block">
                                <a href="http://github.com/LauraChristin">Laura Christin Stempfle</a>

                                ,
                            </span>
                            <span class="author-block">
                                <a href="https://github.com/LksWllmnn">Lukas Willmann</a>

                                ,
                            </span>
                            <span class="author-block">
                                <a href="https://github.com/Simon-Za">Simon Zakowski</a>

                                ,
                            </span>
                            <span class="author-block">
                                <a href="https://github.com/uhahne">Prof. Dr. Uwe Hahne</a>

                            </span>
                        </div>
                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                Hochschule Furtwangen University
                            </span>
                        </div>
                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <span class="link-block">
                                    <a href="./static/paper/Free3D___Free_viewpoint_3D_video_creation.pdf"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                        <span>Paper</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="./static/poster/Free3D_Poster.pdf"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                        <span>Poster</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="https://github.com/HFU-DM-free3D/free3d.github.io"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Code</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="https://bwsyncandshare.kit.edu/s/etCYZpMDzjfYgza"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="far fa-images"></i>
                                        </span>
                                        <span>Data</span>
                                    </a>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <section class="hero teaser">
        <div class="container is-max-desktop">
            <div class="hero-body">
                <video id="teaser" autoplay muted loop playsinline height="100%">
                    <source src="./static/videos/free3d-website-teaser-video.mp4" type="video/mp4">
                </video>
                <h2 class="subtitle has-text-centered">
                    <span class="dnerf">Free3D</span> creates 3D-videos out of 3 Kinect cameras.
            </div>
        </div>
    </section>
    <section class="hero is-light is-small">
        <div class="hero-body">
            <div class="container">
                <div id="results-carousel" class="carousel results-carousel">
                    <div class="item item-steve">
                        <video poster="" id="" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/000.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-chair-tp">
                        <video poster="" id="" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/001.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-shiba">
                        <video poster="" id="" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/002.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-fullbody">
                        <video poster="" id="" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/003.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-blueshirt">
                        <video poster="" id="" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/004.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-mask">
                        <video poster="" id="" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/005.mp4" type="video/mp4">
                        </video>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <section class="section">
        <div class="container is-max-desktop">
            <!-- Abstract. -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p>This student research project explores the recording of full three-dimensional (3D) scenes
                            using only three Azure Kinect cameras. By leveraging novel methodologies such as Neural
                            Radiance Fields (NeRF) and 3D Gaussian Splatting,
                            the captured images are processed into a "4D data structure", enabling the creation of new
                            videos from any perspective. The project's goal is to determine the extent to which visually
                            high-quality 3D scenes can be generated
                            with minimal equipment. The study highlights the potential of these advanced techniques to
                            enhance for example online learning experiences by providing an accessible tool for creating
                            immersive 3D content. Experiments demonstrated
                            that using depth data from RGB-D cameras compensates for the reduced number of input images,
                            maintaining high visual quality. The results show that combining static Gaussian
                            Splatting-generated backgrounds with point cloud
                            data from Azure Kinect cameras can produce impressive 3D scene reconstructions with reduced
                            computational demands, making the technology more accessible and cost-effective.</p>
                    </div>
                </div>
            </div>

        </div>
    </section>
    <section class="section">
        <div class="container is-max-desktop">

            <div class="columns is-centered">
                <div class="column is-full-width">
                    <h2 class="title is-3">Infrastructure</h2>


                    <h3 class="title is-4">Hardware Setup</h3>


                    <div class="columns is-centered">

                        <div class="column">
                            <div class="content">
                                <h4 class=" is-3">Time Lapse Setup</h4>
                                <p class="hscp">
                                    It takes approximately seven minutes for two people to set up the hardware, which
                                    consists of three Azure Kinect cameras on tripods connected via cables to each other
                                    and a laptop each.
                                </p>
                                <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
                                    <source src="./static/videos/Zeitraffer_cut.mp4" type="video/mp4">
                                </video>
                            </div>
                        </div>

                        <div class="column">
                            <div class="content">

                                <h4 class=" is-3">Kinect Setup</h4>
                                <p class="hscp">
                                    The illustration shows the setup of the three Azure Kinect cameras. They are
                                    connected by two AUX cables. Each from the sync out to the sync in of the next. The
                                    camera connected via sync out only is the master, the other two are subs. They are
                                    powered
                                    and connected to the laptops via the USB-C port.
                                </p>
                                <div class="">
                                    <img src="./static/images/Kinect_Set-Up.jpg" alt="Kinect-Set-Up"
                                        title="Kinect-Set-Up">
                                </div>
                            </div>
                        </div>
                    </div>

                    <h3 class="title is-4">Software Setup</h3>

                    <div class="columns is-centered">
                        <div class="column">
                            <div class="content">
                                <h4 class=" is-3">Network Infrastructure</h4>
                                <p class="soscp">
                                    Our small setup was implemented without any kind of DHCP server. We had only four IP
                                    addresses to use, so we assigned them manually to the PCs. The PC with the IP
                                    address 192.168.10.1 uses the Windows Network Share feature to share a specific
                                    folder across
                                    the entire network. This allows all other clients to save their Kinect videos in
                                    that folder, ensuring that all video files are stored centrally. That folder has to
                                    be added as a network folder to all other clients,
                                    so its folder path can be used in the code as the path for the recordings of the
                                    Kinect cameras.
                                </p>
                                <div class="">
                                    <img src="./static/images/physical-infrastructure.png" alt="Physical-Infrastructure"
                                        title="Physical-Infrastructure">
                                </div>
                            </div>
                        </div>
                        <div class="column">
                            <div class="content">
                                <h4 class=" is-3">Basic Overview</h4>
                                <p class="soscp">
                                    In order to reproduce our results, it is important to use 3 Azure Kinect cameras.
                                    Each of these cameras is connected to a laptop or PC as shown in the container âFor
                                    each kinectâ. The recorder will run on this device, which will connect to the
                                    websocket
                                    server and needs access to a central file system so that the recorded video can be
                                    saved on it. The websocket server, Calibrator and the Operator Client are executed
                                    on another laptop or PC. This device also provides
                                    the central file system. If all recorders and the calibrator are connected, both the
                                    recordings and the calibration can be started centrally via the Operator Client.
                                </p>
                                <div class="">
                                    <img src="./static/images/Hierachy.png" alt="Infrastructure" title="Infrastructure">
                                </div>
                            </div>
                        </div>
                    </div>
                    <h2 class="title is-3">Marker Based Calibration</h2>

                    <div class="columns is-centered">

                        <div class="column">
                            <div class="content">

                                <h3 class=" is-3">ArUco Marker</h3>
                                <p>
                                    An ArUco marker cube (17 cm edge length) with unique IDs on each side is used to
                                    calculate the cube's center from the tracked markers in the camera images. The
                                    cube's center is then set as the scene center for determining camera positions and
                                    orientations.
                                    Due to marker size and lighting, tracking inaccuracies may occur. Over a ten-second
                                    recording at 30 frames per second, up to 300 orientation matrix and position vector
                                    results per marker ID are generated. An algorithm
                                    compares pairs of detected marker positions, with the median of these comparisons
                                    determining the camera position relative to the cube.
                                </p>
                                <div class="">
                                    <img src="./static/images/TrackedMarkers.png" alt="ArUco Marker"
                                        title="ArUco Marker">
                                </div>
                            </div>
                        </div>

                        <div class="column">
                            <div class="content">

                                <h3 class=" is-3">ChArUco Board</h3>
                                <p>
                                    A ChArUco board was also created, printed on an A1 poster. The ArUco markers are
                                    11.2 cm x 11.2 cm, and the chessboard squares are 15 cm x 15 cm. In a ten-second
                                    calibration video at 30 frames per second, up to 300 orientation matrices and
                                    position vectors
                                    are generated. OpenCV outputs a single position, and the median of these results is
                                    used to determine the poster's position, which in turn is used to determine the
                                    camera position.
                                </p>
                                <div class="">
                                    <img src="./static/images/TrackedMarkers_Charuco.png" alt="ChArUco Board"
                                        title="ChArUco Board">
                                </div>
                            </div>
                        </div>
                    </div>
                    <h2 class="title is-3">Post-Processing</h2>

                    <div class="columns is-centered">

                        <div class="column">
                            <div class="content">

                                <h3 class="ppc is-3">From whole room to extracted center</h3>
                                <p>
                                    RGB-D data from MKV files is processed with calibration data to form the point
                                    cloud. Open3D functions extract the central object or person and DB-Scan selects the
                                    largest cluster, typically the desired object. The ground is removed with a surface
                                    selection
                                    function. These steps isolate the object in the scene, though errors may occur
                                    depending on the scene.
                                </p>
                                <div class="">
                                    <div class="columns is-centered">
                                        <div class="column">
                                            <img src="./static/images/Pointcloud_Kinects.png" alt="PointCloud"
                                                title="PointCloud">
                                            <img src="./static/images/PlaneSegmentation.png" alt="PlaneSegmentation"
                                                title="PlaneSegmentation">
                                        </div>
                                        <div class="column">
                                            <img src="./static/images/DB_Scan.png" alt="DB_Scan" title="DB_Scan">
                                            <img src="./static/images/ExtractetObjectInCenter.png"
                                                alt="ExtractetObjectInCenter" title="ExtractetObjectInCenter">
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>

                        <div class="column">
                            <div class="content">

                                <h3 class="ppc is-3"> Combining Point Clouds and Gaussian Splats</h3>
                                <p>
                                    To visualize the point clouds, we used Unity with a Gaussian Splat integration to
                                    display PLY files. We developed a custom plugin to animate and display point clouds
                                    in Unity. The picture below shows the successful combination, featuring the typical
                                    appearance
                                    of a Gaussian Splat with our point cloud in the center.
                                </p>
                                <div class="">
                                    <img src="./static/images/GS_Unity.png" alt="Unity" title="Unity">
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Concurrent Work. -->
            <div class="columns is-centered">
                <div class="column is-full-width">
                    <h2 class="title is-3">Related Links</h2>
                    <div class="content has-text-justified">
                        <p>
                            There's a lot of excellent work that inspired us:
                        </p>
                        <p>
                            <a href="http://arxiv.org/abs/2003.08934">NeRF</a> provided revolutionary results on novel
                            view synthesis.
                        </p>
                        <p>
                            <a href="http://arxiv.org/abs/2310.08585">Im4D</a> and
                            <a href="http://arxiv.org/abs/2310.11448">4k4D</a> provides the creation of 3D-videos
                            through dynamic NeRFs.
                        </p>
                        <p>
                            Some work, that created 3D-videos through dynamic gaussian spaltting:
                            <a href="http://arxiv.org/abs/2308.09713"> Dynamic 3D Gaussians</a> .
                        </p>
                    </div>
                </div>
            </div>
            <!--/ Concurrent Work. -->
        </div>
    </section>
    <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <h2 class="title">BibTeX</h2>
            <pre>
                            <code>
@article{brunn2024free3d,
    author    = {Brunn, Felix and Christmeier, Jan and HÃ¤cker, Nick P. and Stempfle, Laura C. and Willmann, Lukas and Zakowski, Simon and Hahne, Prof. Dr. Uwe},
    title     = {Free3D - Free-viewpoint 3D video creation},
    year      = {2024}
}
                            </code>
                        </pre>
        </div>
    </section>
    <footer class="footer">
        <div class="container">
            <div class="content has-text-centered">
                <a class="icon-link" href="./static/videos/nerfies_paper.pdf">
                    <i class="fas fa-file-pdf"></i>
                </a>
                <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
                    <i class="fab fa-github"></i>
                </a>
            </div>
            <div class="columns is-centered">
                <div class="column is-8">
                    <div class="content">
                        <p>
                            This website is licensed under a
                            <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">
                                Creative
                                Commons Attribution-ShareAlike 4.0 International License
                            </a> .
                        </p>
                        <p>
                            This means you are free to borrow the
                            <a href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website, we
                            just ask that you link back to this page in the footer. Please remember to remove the
                            analytics code included in the header of the website
                            which you do not want on your website.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </footer>
</body>

</html>